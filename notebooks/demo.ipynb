{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be able to make edits to repo without having to restart notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import yaml\n",
    "import json\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import mongomock\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import fsspec\n",
    "from fsspec.implementations.local import LocalFileSystem\n",
    "from pathlib import Path\n",
    "\n",
    "from src.store.data_access_objects import (\n",
    "    MongoDAO,\n",
    "    FileSystemDAO,\n",
    "    InMemoryObjectDAO,\n",
    "    datetime_to_microseconds,\n",
    "    microseconds_to_datetime,\n",
    ")\n",
    "\n",
    "from src.store.repositories import (\n",
    "    DomainModelRepository, domain_model_json_schema,\n",
    "    DataRepository,\n",
    "    InMemoryObjectRepository,\n",
    ")\n",
    "\n",
    "from src.store.datafile_adapters import (\n",
    "    XarrayDataArrayNetCDFAdapter,\n",
    "    XarrayDataArrayZarrAdapter,\n",
    "    AbstractDataFileAdapter,\n",
    ")\n",
    "\n",
    "from src.store import UnitOfWorkProvider\n",
    "from datetime import datetime, timezone, timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def deserialize_dataarray(data_object):\n",
    "        \"\"\"Deserializes a data object.\n",
    "        Arguments:\n",
    "            data_object {dict} -- The data object to deserialize.\n",
    "        Returns:\n",
    "            dict -- The deserialized data object.\n",
    "        \"\"\"\n",
    "        attrs = data_object.attrs.copy()\n",
    "        for key, value in attrs.items():\n",
    "            if isinstance(value, str):\n",
    "                value = value.replace(\"'\", '\"')\n",
    "                if value.lower() == 'true':\n",
    "                    attrs[key] = True\n",
    "                elif value.lower() == 'false':\n",
    "                    attrs[key] = False\n",
    "                elif value.lower() == 'none':\n",
    "                    attrs[key] = None\n",
    "                elif value.startswith('{'):\n",
    "                    attrs[key] = json.loads(value)\n",
    "            if isinstance(value, np.ndarray):\n",
    "                attrs[key] = value.tolist()\n",
    "        data_object.attrs = attrs\n",
    "        return data_object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock DB client\n",
    "mongo_client = mongomock.MongoClient()\n",
    "\n",
    "# Demo filesystem\n",
    "tmpdir =  Path.cwd().parent / r\"data\" / r\"internal\"\n",
    "tmpdir = pathlib.Path(tmpdir)\n",
    "filesystem = LocalFileSystem(root=str(tmpdir))\n",
    "\n",
    "# Empty memory store for demo\n",
    "memory_store = dict()\n",
    "\n",
    "# Get uow to act on database\n",
    "uow_provider = UnitOfWorkProvider(mongo_client, filesystem, memory_store)\n",
    "unit_of_work = uow_provider(str(tmpdir))\n",
    "\n",
    "# Get raw_property_models\n",
    "property_models_path = Path.cwd().parent / r\"tests\" / r\"data\" / r\"valid_data\" / r\"models\" / r\"property_models.json\"\n",
    "with open(property_models_path, 'r') as file:\n",
    "    raw_property_models = json.load(file)\n",
    "\n",
    "# Get raw_metamodels\n",
    "metamodels_dir = Path.cwd().parent / r\"tests\" / r\"data\" / r\"valid_data\" / r\"models\" / r\"metamodels\"\n",
    "metamodel_filepaths = list(metamodels_dir.glob(\"*.json\"))\n",
    "raw_metamodels = []\n",
    "for filepath in metamodel_filepaths:\n",
    "    with open(filepath, 'r') as file:\n",
    "        raw_metamodels.append(json.load(file))\n",
    "\n",
    "# Get raw_data_models\n",
    "data_models_dir = Path.cwd().parent / r\"tests\" / r\"data\" / r\"valid_data\" / r\"models\" / r\"data_models\"\n",
    "data_model_filepaths = list(data_models_dir.glob(\"*.json\"))\n",
    "raw_data_models = []\n",
    "for filepath in data_model_filepaths:\n",
    "    with open(filepath, 'r') as file:\n",
    "        raw_data_models.append(json.load(file))\n",
    "\n",
    "# Get raw_records\n",
    "netcdf_dir = Path.cwd().parent / r\"data\" / r\"input\"\n",
    "records_files = list(netcdf_dir.glob(\"*.xlsx\"))\n",
    "raw_records = []\n",
    "for filepath in records_files:\n",
    "        file = pd.read_excel(filepath, engine='openpyxl', dtype=str) \n",
    "        file_json = file.to_json(orient=\"records\")\n",
    "        records = json.loads(file_json)\n",
    "        raw_records.extend(records)\n",
    "\n",
    "# Get dataarrays\n",
    "netcdf_dir = Path.cwd().parent / r\"data\" / r\"input\"\n",
    "netcdf_files = list(netcdf_dir.glob(\"*.nc\"))\n",
    "dataarrays = []\n",
    "for filepath in netcdf_files:\n",
    "    dataarray = xr.open_dataarray(filepath)\n",
    "    dataarray = deserialize_dataarray(dataarray)\n",
    "    dataarrays.append(dataarray)\n",
    "\n",
    "# Add property models, metamodels, data models, and records\n",
    "with unit_of_work as uow:\n",
    "    for property_model in raw_property_models:\n",
    "        uow.domain_models.add(property_model)\n",
    "    for metamodel in raw_metamodels:\n",
    "        uow.domain_models.add(metamodel)\n",
    "    for data_model in raw_data_models:\n",
    "        uow.domain_models.add(data_model)\n",
    "    for record in raw_records:\n",
    "        if not record.get(\"has_file\"):\n",
    "            uow.data.add(record)\n",
    "    for dataarray in dataarrays:\n",
    "        if not dataarray.attrs.get(\"schema_ref\") == \"test\":\n",
    "            uow.data.add(dataarray)\n",
    "    uow.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "backend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
