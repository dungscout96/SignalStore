{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be able to make edits to repo without having to restart notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "import json\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import mongomock\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from fsspec.implementations.local import LocalFileSystem\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from signalstore import UnitOfWorkProvider\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def deserialize_dataarray(data_object):\n",
    "        \"\"\"Deserializes a data object.\n",
    "        Arguments:\n",
    "            data_object {dict} -- The data object to deserialize.\n",
    "        Returns:\n",
    "            dict -- The deserialized data object.\n",
    "        \"\"\"\n",
    "        attrs = data_object.attrs.copy()\n",
    "        for key, value in attrs.items():\n",
    "            if isinstance(value, str):\n",
    "                value = value.replace(\"'\", '\"')\n",
    "                if value.lower() == 'true':\n",
    "                    attrs[key] = True\n",
    "                elif value.lower() == 'false':\n",
    "                    attrs[key] = False\n",
    "                elif value.lower() == 'none':\n",
    "                    attrs[key] = None\n",
    "                elif value.startswith('{'):\n",
    "                    attrs[key] = json.loads(value)\n",
    "            if isinstance(value, np.ndarray):\n",
    "                attrs[key] = value.tolist()\n",
    "        data_object.attrs = attrs\n",
    "        return data_object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock DB client\n",
    "mongo_client = mongomock.MongoClient()\n",
    "\n",
    "# Demo filesystem\n",
    "tmpdir =  Path.cwd().parent / r\"data\" / r\"internal\"\n",
    "tmpdir = pathlib.Path(tmpdir)\n",
    "filesystem = LocalFileSystem(root=str(tmpdir))\n",
    "# clear tmpdir\n",
    "for file in filesystem.ls(tmpdir):\n",
    "    filesystem.rm(file)\n",
    "\n",
    "# Empty memory store for demo\n",
    "memory_store = dict()\n",
    "\n",
    "# Get uow to act on database\n",
    "uow_provider = UnitOfWorkProvider(mongo_client, filesystem, memory_store)\n",
    "unit_of_work = uow_provider(str(tmpdir))\n",
    "\n",
    "# Get raw_property_models\n",
    "property_models_path = Path.cwd().parent / r\"tests\" / r\"data\" / r\"valid_data\" / r\"models\" / r\"property_models.json\"\n",
    "with open(property_models_path, 'r') as file:\n",
    "    raw_property_models = json.load(file)\n",
    "\n",
    "# Get raw_metamodels\n",
    "metamodels_dir = Path.cwd().parent / r\"tests\" / r\"data\" / r\"valid_data\" / r\"models\" / r\"metamodels\"\n",
    "metamodel_filepaths = list(metamodels_dir.glob(\"*.json\"))\n",
    "raw_metamodels = []\n",
    "for filepath in metamodel_filepaths:\n",
    "    with open(filepath, 'r') as file:\n",
    "        raw_metamodels.append(json.load(file))\n",
    "\n",
    "# Get raw_data_models\n",
    "data_models_dir = Path.cwd().parent / r\"tests\" / r\"data\" / r\"valid_data\" / r\"models\" / r\"data_models\"\n",
    "data_model_filepaths = list(data_models_dir.glob(\"*.json\"))\n",
    "raw_data_models = []\n",
    "for filepath in data_model_filepaths:\n",
    "    with open(filepath, 'r') as file:\n",
    "        raw_data_models.append(json.load(file))\n",
    "\n",
    "# Get raw_records\n",
    "netcdf_dir = Path.cwd().parent / r\"data\" / r\"input\"\n",
    "records_files = list(netcdf_dir.glob(\"*.xlsx\"))\n",
    "raw_records = []\n",
    "for filepath in records_files:\n",
    "        file = pd.read_excel(filepath, engine='openpyxl', dtype=str)\n",
    "        file_json = file.to_json(orient=\"records\")\n",
    "        records = json.loads(file_json)\n",
    "        raw_records.extend(records)\n",
    "\n",
    "# Get dataarrays\n",
    "netcdf_dir = Path.cwd().parent / r\"data\" / r\"input\"\n",
    "netcdf_files = list(netcdf_dir.glob(\"*.nc\"))\n",
    "dataarrays = []\n",
    "for filepath in netcdf_files:\n",
    "    dataarray = xr.open_dataarray(filepath)\n",
    "    dataarray = deserialize_dataarray(dataarray)\n",
    "    dataarrays.append(dataarray)\n",
    "\n",
    "# Add property models, metamodels, data models, and records\n",
    "with unit_of_work as uow:\n",
    "    for property_model in raw_property_models:\n",
    "        uow.domain_models.add(property_model)\n",
    "    for metamodel in raw_metamodels:\n",
    "        uow.domain_models.add(metamodel)\n",
    "    for data_model in raw_data_models:\n",
    "        uow.domain_models.add(data_model)\n",
    "    for record in raw_records:\n",
    "        if not record.get(\"has_file\"):\n",
    "            uow.data.add(record)\n",
    "    for dataarray in dataarrays:\n",
    "        if not dataarray.attrs.get(\"schema_ref\") == \"test\":\n",
    "            uow.data.add(dataarray)\n",
    "    uow.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with unit_of_work as uow:\n",
    "    query = {\n",
    "        \"schema_ref\": \"session\"\n",
    "    }\n",
    "    sorted_by = [(\"session_start\", -1)]\n",
    "    sessions = uow.data.find(query)\n",
    "    print(sessions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with unit_of_work as uow:\n",
    "    query = {\n",
    "        \"session_data_ref\": {'schema_ref': 'session', 'data_name': 'NON-73-6_1_20180606_101138'},\n",
    "        \"probe_data_ref\": {'schema_ref': 'probe', 'data_name': '1'}\n",
    "    }\n",
    "    data = uow.data.find(query)\n",
    "    data = xr.Dataset({d[\"schema_ref\"]: uow.data.get(d[\"schema_ref\"], d[\"data_name\"]) for d in data})\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_colored_waveforms(data, ax=None):\n",
    "    \"\"\"Plot waveforms colored by spike_labels\"\"\"\n",
    "    # use xarray operations to filter waveforms by spike_labels\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    unique_labels = data.spike_labels.unique()\n",
    "    for label in unique_labels:\n",
    "        filtered_data = data.where(data.spike_labels == label, drop=True)\n",
    "        ax.plot(filtered_data.waveform, label=label)\n",
    "    ax.legend()\n",
    "    return ax"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "backend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
